# WebSocket Integration Guide
## How VoiceChatController connects to ConversationController

---

## ğŸ“Š Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         UI LAYER                                  â”‚
â”‚  (voice_chat.dart - User clicks mic button)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VOICE CHAT CONTROLLER                          â”‚
â”‚  (voice_chat_controller.dart)                                    â”‚
â”‚                                                                   â”‚
â”‚  â€¢ Manages UI state (isListening, isSpeaking, etc.)              â”‚
â”‚  â€¢ Handles user interactions                                     â”‚
â”‚  â€¢ Creates and manages ConversationController instance           â”‚
â”‚  â€¢ Bridges UI â†” WebSocket logic                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CONVERSATION CONTROLLER                          â”‚
â”‚  (conversation_controller.dart)                                   â”‚
â”‚                                                                   â”‚
â”‚  â€¢ Orchestrates WebSocket conversation flow                      â”‚
â”‚  â€¢ Manages state machine (idle â†’ connecting â†’ listening â†’ etc.)  â”‚
â”‚  â€¢ Coordinates: VoiceWsClient, MicStreamer, TtsPlayer            â”‚
â”‚  â€¢ Handles barge-in detection                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LOW-LEVEL COMPONENTS                         â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ VoiceWsClient   â”‚  â”‚  MicStreamer    â”‚  â”‚   TtsPlayer     â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚
â”‚  â”‚ â€¢ WebSocket     â”‚  â”‚ â€¢ Mic capture   â”‚  â”‚ â€¢ Audio play    â”‚  â”‚
â”‚  â”‚ â€¢ Send/Receive  â”‚  â”‚ â€¢ PCM16 frames  â”‚  â”‚ â€¢ PCM16 decode  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚BargeInDetector  â”‚                                             â”‚
â”‚  â”‚                 â”‚                                             â”‚
â”‚  â”‚ â€¢ RMS analysis  â”‚                                             â”‚
â”‚  â”‚ â€¢ Interrupt det â”‚                                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— Connection Flow: toggleListening() â†’ startSession()

### **STEP-BY-STEP INTEGRATION:**

```dart
// ============================================================================
// STEP 1: User clicks mic button in UI
// ============================================================================
// File: voice_chat.dart
GestureDetector(
  onTap: () => controller.toggleListening(),
  child: MicIcon(),
)

// ============================================================================
// STEP 2: VoiceChatController.toggleListening() is called
// ============================================================================
// File: voice_chat_controller.dart
Future<void> toggleListening() async {
  if (isListening.value) {
    // Stop WebSocket conversation
    await stopListening();
  } else {
    // Start WebSocket conversation
    await startListening();
  }
}

// ============================================================================
// STEP 3: VoiceChatController.startListening() creates ConversationController
// ============================================================================
Future<void> startListening() async {
  if (!isListening.value) {
    isListening.value = true;
    _startAnimation();

    // Create ConversationController instance with all components
    _conversationController = ConversationController(
      ws: VoiceWsClient(),
      mic: MicStreamer(
        sampleRate: 16000,
        numChannels: 1,
        frameMs: 20,
      ),
      player: TtsPlayer(
        sampleRate: 24000,
        numChannels: 1,
      ),
      bargeIn: BargeInDetector(
        threshold: 0.02,
        requiredFrames: 3,
      ),
    );

    // ========================================================================
    // STEP 4: Call ConversationController.startSession() - THE BRIDGE!
    // ========================================================================
    try {
      await _conversationController!.startSession(
        wsUri: Uri.parse('wss://your-server.com/voice'),
        scenario: scenarioData?.scenarioTitle ?? 'General Conversation',
      );
      
      // Start listening to conversation state changes
      _listenToConversationState();
      
    } catch (e) {
      print('Error starting conversation: $e');
      isListening.value = false;
      _stopAnimation();
    }
  }
}

// ============================================================================
// STEP 5: Listen to ConversationController state changes
// ============================================================================
void _listenToConversationState() {
  // Poll or use a stream to monitor state
  Timer.periodic(Duration(milliseconds: 100), (timer) {
    if (_conversationController == null) {
      timer.cancel();
      return;
    }

    final state = _conversationController!.state;
    
    switch (state) {
      case VoiceState.idle:
        isListening.value = false;
        isSpeaking.value = false;
        break;
        
      case VoiceState.connecting:
        isListening.value = true;
        isSpeaking.value = false;
        break;
        
      case VoiceState.listening:
        isListening.value = true;
        isSpeaking.value = false;
        break;
        
      case VoiceState.aiSpeaking:
        isListening.value = true;
        isSpeaking.value = true;
        break;
    }
  });
}

// ============================================================================
// STEP 6: Stop conversation when user clicks mic again
// ============================================================================
Future<void> stopListening() async {
  if (isListening.value) {
    await _conversationController?.stopSession();
    _conversationController = null;
    
    isListening.value = false;
    isSpeaking.value = false;
    _stopAnimation();
  }
}
```

---

## ğŸ¯ Complete Data Flow

```
USER CLICKS MIC BUTTON
         â”‚
         â”œâ”€â†’ UI: voice_chat.dart
         â”‚   â””â”€â†’ onTap: controller.toggleListening()
         â”‚
         â”œâ”€â†’ VoiceChatController.toggleListening()
         â”‚   â””â”€â†’ Checks: isListening.value?
         â”‚       â”‚
         â”‚       â”œâ”€â†’ FALSE: Start new conversation
         â”‚       â”‚   â””â”€â†’ VoiceChatController.startListening()
         â”‚       â”‚       â”‚
         â”‚       â”‚       â”œâ”€â†’ Set isListening.value = true
         â”‚       â”‚       â”œâ”€â†’ Start UI animation
         â”‚       â”‚       â”œâ”€â†’ Create ConversationController instance
         â”‚       â”‚       â”‚   â€¢ new VoiceWsClient()
         â”‚       â”‚       â”‚   â€¢ new MicStreamer(16kHz, PCM16)
         â”‚       â”‚       â”‚   â€¢ new TtsPlayer(24kHz, PCM16)
         â”‚       â”‚       â”‚   â€¢ new BargeInDetector()
         â”‚       â”‚       â”‚
         â”‚       â”‚       â””â”€â†’ â­ ConversationController.startSession()
         â”‚       â”‚           â”‚
         â”‚       â”‚           â”œâ”€â†’ state = VoiceState.connecting
         â”‚       â”‚           â”‚
         â”‚       â”‚           â”œâ”€â†’ VoiceWsClient.connect(wsUri)
         â”‚       â”‚           â”‚   â””â”€â†’ Opens WebSocket to server
         â”‚       â”‚           â”‚
         â”‚       â”‚           â”œâ”€â†’ TtsPlayer.init() & start()
         â”‚       â”‚           â”‚   â””â”€â†’ Ready to play AI audio
         â”‚       â”‚           â”‚
         â”‚       â”‚           â”œâ”€â†’ Send session config (JSON)
         â”‚       â”‚           â”‚   {type: "start_session", in_sr: 16000, ...}
         â”‚       â”‚           â”‚
         â”‚       â”‚           â”œâ”€â†’ Send scenario config (JSON)
         â”‚       â”‚           â”‚   {type: "set_scenario", scenario: "..."}
         â”‚       â”‚           â”‚
         â”‚       â”‚           â”œâ”€â†’ Start WebSocket listener
         â”‚       â”‚           â”‚   ws.stream.listen((msg) {
         â”‚       â”‚           â”‚     â€¢ Handle JSON messages (state, transcript, etc.)
         â”‚       â”‚           â”‚     â€¢ Handle binary audio (play via TtsPlayer)
         â”‚       â”‚           â”‚   })
         â”‚       â”‚           â”‚
         â”‚       â”‚           â”œâ”€â†’ MicStreamer.init() & start()
         â”‚       â”‚           â”‚   â””â”€â†’ Start recording microphone
         â”‚       â”‚           â”‚
         â”‚       â”‚           â”œâ”€â†’ Start mic frame listener
         â”‚       â”‚           â”‚   mic.frames.listen((frame) {
         â”‚       â”‚           â”‚     â€¢ Send frame to server via WebSocket
         â”‚       â”‚           â”‚     â€¢ Check for barge-in if AI speaking
         â”‚       â”‚           â”‚   })
         â”‚       â”‚           â”‚
         â”‚       â”‚           â””â”€â†’ state = VoiceState.listening
         â”‚       â”‚
         â”‚       â””â”€â†’ TRUE: Stop conversation
         â”‚           â””â”€â†’ VoiceChatController.stopListening()
         â”‚               â””â”€â†’ ConversationController.stopSession()
         â”‚                   â”œâ”€â†’ Cancel mic subscription
         â”‚                   â”œâ”€â†’ Cancel WebSocket subscription
         â”‚                   â”œâ”€â†’ Stop microphone
         â”‚                   â”œâ”€â†’ Stop audio player
         â”‚                   â”œâ”€â†’ Close WebSocket
         â”‚                   â””â”€â†’ state = VoiceState.idle
         â”‚
         â””â”€â†’ UI updates based on isListening/isSpeaking observable values
```

---

## ğŸ”§ Implementation Checklist

### **Phase 1: Update VoiceChatController**
- [x] Add `ConversationController?` instance variable
- [x] Import required classes (VoiceWsClient, MicStreamer, TtsPlayer, etc.)
- [x] Modify `startListening()` to create ConversationController
- [x] Call `conversationController.startSession()`
- [x] Add state synchronization logic
- [x] Modify `stopListening()` to call `conversationController.stopSession()`

### **Phase 2: Configure WebSocket Server**
- [ ] Set up WebSocket server URL (e.g., wss://your-server.com/voice)
- [ ] Implement server-side STT (Speech-to-Text)
- [ ] Implement server-side AI conversation logic
- [ ] Implement server-side TTS (Text-to-Speech)
- [ ] Test JSON message formats
- [ ] Test binary audio streaming

### **Phase 3: Testing**
- [ ] Test WebSocket connection
- [ ] Test microphone audio upload
- [ ] Test server audio playback
- [ ] Test barge-in detection
- [ ] Test error handling
- [ ] Test session termination

---

## ğŸ“ Key Implementation Notes

### **1. WebSocket URL Configuration**
```dart
// Option 1: Hardcoded (development)
final wsUri = Uri.parse('wss://dev-server.com/voice');

// Option 2: Environment variable
final wsUri = Uri.parse(const String.fromEnvironment('WS_URL'));

// Option 3: From config service
final wsUri = Uri.parse(await ConfigService.getWebSocketUrl());
```

### **2. State Synchronization**
The VoiceChatController needs to sync with ConversationController state:

```dart
// ConversationController.state (internal)
enum VoiceState { idle, connecting, listening, aiSpeaking }

// VoiceChatController observables (for UI)
final isListening = false.obs;  // Maps to: listening | aiSpeaking
final isSpeaking = false.obs;   // Maps to: aiSpeaking
final isProcessing = false.obs; // Maps to: connecting
```

### **3. Error Handling**
```dart
try {
  await _conversationController!.startSession(
    wsUri: wsUri,
    scenario: scenario,
  );
} on WebSocketException catch (e) {
  // Handle WebSocket connection errors
  showErrorToast('Connection failed: ${e.message}');
  isListening.value = false;
} on MicrophoneException catch (e) {
  // Handle microphone errors
  showErrorToast('Microphone error: ${e.message}');
  isListening.value = false;
} catch (e) {
  // Handle general errors
  showErrorToast('Error: $e');
  isListening.value = false;
}
```

### **4. Cleanup on Dispose**
```dart
@override
void onClose() {
  _conversationController?.stopSession();
  _conversationController = null;
  _animationTimer?.cancel();
  super.onClose();
}
```

---

## ğŸš€ Quick Start Implementation

Here's the minimal code to add to `VoiceChatController`:

```dart
// 1. Add import at top
import 'conversation/conversation_controller.dart';
import 'ws/voice_ws_client.dart';
import 'audio/mic_streamer.dart';
import 'audio/tts_player.dart';
import 'audio/barge_in_detector.dart';

// 2. Add instance variable
ConversationController? _conversationController;

// 3. Replace startListening() method
Future<void> startListening() async {
  if (!isListening.value) {
    isListening.value = true;
    _startAnimation();

    _conversationController = ConversationController(
      ws: VoiceWsClient(),
      mic: MicStreamer(sampleRate: 16000, numChannels: 1, frameMs: 20),
      player: TtsPlayer(sampleRate: 24000, numChannels: 1),
      bargeIn: BargeInDetector(threshold: 0.02, requiredFrames: 3),
    );

    await _conversationController!.startSession(
      wsUri: Uri.parse('wss://your-server.com/voice'),
      scenario: scenarioData?.scenarioTitle ?? 'General',
    );
  }
}

// 4. Replace stopListening() method
Future<void> stopListening() async {
  if (isListening.value) {
    await _conversationController?.stopSession();
    _conversationController = null;
    isListening.value = false;
    _stopAnimation();
  }
}

// 5. Update onClose()
@override
void onClose() {
  _conversationController?.stopSession();
  _animationTimer?.cancel();
  super.onClose();
}
```

---

## ğŸ¬ Conclusion

**The bridge between `VoiceChatController.toggleListening()` and `ConversationController.startSession()` is:**

1. User clicks mic â†’ `toggleListening()` called
2. `toggleListening()` calls `startListening()`
3. `startListening()` creates `ConversationController` instance
4. `startListening()` calls `conversationController.startSession(wsUri, scenario)`
5. `startSession()` executes the entire WebSocket workflow (9 initialization steps)
6. Conversation runs in real-time with barge-in support
7. User clicks mic again â†’ `stopListening()` â†’ `conversationController.stopSession()`

This creates a clean separation of concerns:
- **VoiceChatController**: UI state management, user interactions
- **ConversationController**: WebSocket orchestration, audio streaming, state machine
- **Low-level components**: Individual responsibilities (WebSocket, mic, player, detection)
